apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    recommender.ai.gke.io/inference-server: vllm
  generation: 3
  labels:
    app: qwen3-8b-vllm-app
    recommender.ai.gke.io/inference-server: vllm
  name: qwen3-8b
  namespace: models-ns
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: qwen3-8b-vllm-app
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        recommender.ai.gke.io/inference-server: vllm
      labels:
        ai.gke.io/inference-server: vllm
        ai.gke.io/model: qwen.qwen3-8b
        app: qwen3-8b-vllm-app
        recommender.ai.gke.io/inference-server: vllm
    spec:
      containers:
      - command:
          - vllm
        args:
          - serve
          - Qwen/Qwen3-8B
          - --host=0.0.0.0
          - --port=8000
          - --gpu-memory-utilization=.80
          - --max-model-len=32768
          - --tensor-parallel-size=2
          - --swap-space=16
          - --served-model-name=qwen.qwen3-8b
          - --enable-auto-tool-choice
          - --tool-call-parser=hermes
          - --chat-template=/etc/vllm/templates/qwen3_nonthinking.jinja
        env:
        - name: MODEL_ID
          value: Qwen/Qwen3-8B
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              key: hf_api_token
              name: hugging-face-token-secret
        - name: PATH
          value: /usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
        - name: LD_LIBRARY_PATH
          value: /usr/local/nvidia/lib:/usr/local/nvidia/lib64
        image: vllm/vllm-openai:latest
        imagePullPolicy: IfNotPresent
        name: qwen3-8b
        ports:
        - containerPort: 8000
          name: metrics
          protocol: TCP
        readinessProbe:
          failureThreshold: 60
          httpGet:
            path: /health
            port: 8000
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        resources:
            limits:
              cpu: '9'
              ephemeral-storage: 80Gi
              memory: 34Gi
              nvidia.com/gpu: '2'
            requests:
              cpu: '9'
              ephemeral-storage: 80Gi
              memory: 34Gi
              nvidia.com/gpu: '2'
        securityContext:
          capabilities:
            drop:
            - NET_RAW
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /dev/shm
          name: dshm
        - name: jinja-template-volume
          mountPath: /etc/vllm/templates
          readOnly: true
      dnsPolicy: ClusterFirst
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-l4
        cloud.google.com/gke-accelerator-count: '2'
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        seccompProfile:
          type: RuntimeDefault
      terminationGracePeriodSeconds: 30
      tolerations:
      - effect: NoSchedule
        key: kubernetes.io/arch
        operator: Equal
        value: amd64
      - effect: NoSchedule
        key: cloud.google.com/gke-accelerator
        operator: Equal
        value: nvidia-l4
      - effect: NoSchedule
        key: cloud.google.com/machine-family
        operator: Exists
      volumes:
      - emptyDir:
          medium: Memory
        name: dshm
      - name: jinja-template-volume
        configMap:
          name: qwen3-nonthinking-jinja-config
