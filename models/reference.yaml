apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: gemma-3-4b-it-app
    examples.ai.gke.io/deployment-id: gemma-3-4b-it-No3kL
    examples.ai.gke.io/deployment-path: aire
    recommender.ai.gke.io/generated: 'true'
    recommender.ai.gke.io/inference-server: vllm
  name: gemma-3-4b-it
  namespace: models-ns
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: gemma-3-4b-it-app
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        recommender.ai.gke.io/generated: 'true'
        recommender.ai.gke.io/inference-server: vllm
      labels:
        ai.gke.io/inference-server: vllm
        ai.gke.io/model: google.gemma-3-4b-it
        app: gemma-3-4b-it-app
        examples.ai.gke.io/applied-by: gke-aiml-ui
        examples.ai.gke.io/deployment-id: gemma-3-4b-it-No3kL
        examples.ai.gke.io/deployment-path: aire
        examples.ai.gke.io/source: blueprints
        recommender.ai.gke.io/generated: 'true'
        recommender.ai.gke.io/inference-server: vllm
    spec:
      containers:
        - command:
            - vllm
          args:
            - serve
            - google/gemma-3-4b-it
            - --host=0.0.0.0
            - --port=8000
            - --gpu-memory-utilization=.89
            - --max-num-batched-tokens=512
            - --max-num-seqs=128
            - --max-model-len=2048
            - --tensor-parallel-size=1
            - --served-model-name=google.gemma-3-4b-it
            - --enable-auto-tool-choice
            - --tool-call-parser=pythonic
          env:
            - name: MODEL_ID
              value: google/gemma-3-4b-it
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  key: hf_api_token
                  name: gemma-3-4b-it-secret
            - name: PATH
              value: /usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
            - name: LD_LIBRARY_PATH
              value: /usr/local/nvidia/lib:/usr/local/nvidia/lib64
          image: vllm/vllm-openai:latest
          imagePullPolicy: IfNotPresent
          name: gemma-3-4b-it
          ports:
            - containerPort: 8000
              name: metrics
              protocol: TCP
          readinessProbe:
            failureThreshold: 600
            httpGet:
              path: /health
              port: 8000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              nvidia.com/gpu: '1'
            requests:
              nvidia.com/gpu: '1'
          securityContext:
            capabilities:
              drop:
                - NET_RAW
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - mountPath: /dev/shm
              name: dshm
      dnsPolicy: ClusterFirst
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-l4
        cloud.google.com/gke-accelerator-count: '1'
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        seccompProfile:
          type: RuntimeDefault
      terminationGracePeriodSeconds: 30
      tolerations:
        - effect: NoSchedule
          key: kubernetes.io/arch
          operator: Equal
          value: amd64
        - effect: NoSchedule
          key: cloud.google.com/gke-accelerator
          operator: Equal
          value: nvidia-l4
        - effect: NoSchedule
          key: cloud.google.com/machine-family
          operator: Exists
      volumes:
        - emptyDir:
            medium: Memory
          name: dshm
